# ðŸ—ï¸ SiteLenz: Building Defect Classification System

AI-powered system for detecting and classifying building defects using Vision Transformer (ViT).

## ðŸŽ¯ Project Overview

**Detects 7 types of building defects:**
- Algae growth
- Major cracks
- Minor cracks  
- Peeling paint
- Plain (normal surface)
- Spalling concrete
- Stains

## ðŸ“ Project Structure

```
SiteLenz/
â”œâ”€â”€ inference.ipynb          # ðŸš€ Main notebook - Load model & predict
â”œâ”€â”€ models/                  # ðŸ“¦ Place trained .pth file here
â”‚   â””â”€â”€ vit_weights.pth     # Your trained model (download from Kaggle)
â”œâ”€â”€ data/                    # ðŸ“Š Dataset (train/val/test splits)
â”‚   â”œâ”€â”€ train/              # Training images (by class)
â”‚   â”œâ”€â”€ val/                # Validation images  
â”‚   â””â”€â”€ test/               # Test images
â”œâ”€â”€ sample images/           # ðŸ–¼ï¸ Sample defect images
â”œâ”€â”€ code/
â”‚   â””â”€â”€ output analysis/    # ðŸ“ˆ Analysis notebooks
â”œâ”€â”€ requirements.txt         # ðŸ“‹ Python dependencies
â””â”€â”€ verify_models.py        # âœ… Verify .pth files
```

## ðŸš€ Quick Start

### 1. Setup Environment

```bash
pip install -r requirements.txt
```

### 2. Add Your Trained Model

Download `vit_weights.pth` from Kaggle and place it in the `models/` folder.

### 3. Run Inference

Open `inference.ipynb` in Jupyter/VS Code and run all cells.

## ðŸ“Š Model Specifications

- **Architecture**: Vision Transformer (ViT-Base-Patch16-224)
- **Parameters**: ~86 million
- **Input Size**: 224Ã—224 RGB images
- **Output**: 7 defect classes with confidence scores
- **Model Size**: ~330 MB

## ðŸ” Usage Examples

### Single Image Prediction

```python
from inference import predict_image

prediction, confidence = predict_image(
    'sample images/class_images/major crack/crack (1).jpg',
    model, CLASS_NAMES, device
)
print(f"Prediction: {prediction} ({confidence*100:.1f}% confidence)")
```

### Batch Prediction

```python
# Predict all images in test dataset
accuracy, predictions, labels = evaluate_model(model, test_loader, device)
print(f"Test Accuracy: {accuracy:.2f}%")
```

## ðŸ“ˆ Performance

- **Test Accuracy**: Check confusion matrix in `inference.ipynb`
- **Training Time**: ~4-5 hours on Kaggle GPU T4 x2
- **Inference Speed**: ~50-100 images/second on GPU

## ðŸ› ï¸ Tools & Technologies

- **PyTorch**: Deep learning framework
- **timm**: Vision Transformer implementation
- **scikit-learn**: Metrics and evaluation
- **matplotlib/seaborn**: Visualization

## ðŸ“ Requirements

```
torch>=2.0.0
torchvision>=0.15.0
timm>=0.9.0
numpy>=1.24.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
pillow>=9.5.0
```

## ðŸŽ“ Model Training

This project uses a pre-trained Vision Transformer model fine-tuned on building defect images. Training was performed on Kaggle with:
- 200 epochs
- AdamW optimizer
- Mixed precision training (FP16)
- Data augmentation

## ðŸ“§ Contact

For questions or issues, please open an issue on GitHub.

---

**Status**: âœ… Production Ready | Last Updated: October 2025
